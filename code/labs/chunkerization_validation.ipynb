{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunkerization\n",
    "\n",
    "Estudiaremos las siguientes métricas:\n",
    "\n",
    "### Context Relevancy\n",
    "This metric gauges the relevancy of the retrieved context, calculated based on both the question and contexts. The values fall within the range of (0, 1), with higher values indicating better relevancy.Ideally, the retrieved context should exclusively contain essential information to address the provided query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "3. crear chunks sobre html artículos genérico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "import pickle\n",
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "loader = PyPDFLoader(\"../data/Constitución Española/Constitución española.pdf\")\n",
    "documents = loader.load()\n",
    "for document in documents:\n",
    "    document.metadata['filename'] = document.metadata['source']\n",
    "\n",
    "path = \"../data/Constitución Española/\"\n",
    "chunk_path = path + \"chunks/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. CharacterSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_sizes = [200, 300, 400]\n",
    "\n",
    "for i in chunk_sizes:\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        chunk_size=i,\n",
    "        chunk_overlap=i/10,\n",
    "        length_function=len,\n",
    "        separator = '',\n",
    "        is_separator_regex=False\n",
    "    )\n",
    "\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "\n",
    "    # Define the file path\n",
    "    file_path = chunk_path + f\"documents_charactersplitter_{i}.pkl\"\n",
    "\n",
    "    # Save the texts variable to a file\n",
    "    with open(file_path, \"wb\") as file:\n",
    "        pickle.dump(texts, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitters = {}\n",
    "for i in chunk_sizes:\n",
    "    # Define the file path\n",
    "    file_path = chunk_path + f\"documents_charactersplitter_{i}.pkl\"\n",
    "\n",
    "    # Load the texts from the pickle file\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        splitters[f\"charactersplitter_{i}\"] = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. RecursiveCharacterSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_sizes = [200, 300, 400]\n",
    "\n",
    "for i in chunk_sizes:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=i,\n",
    "        chunk_overlap=i/10,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False\n",
    "    )\n",
    "\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "\n",
    "    # Define the file path\n",
    "    file_path = chunk_path + f\"documents_recursivecharactersplitter_{i}.pkl\"\n",
    "\n",
    "    # Save the texts variable to a file\n",
    "    with open(file_path, \"wb\") as file:\n",
    "        pickle.dump(texts, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in chunk_sizes:\n",
    "    # Define the file path\n",
    "    file_path = chunk_path + f\"documents_recursivecharactersplitter_{i}.pkl\"\n",
    "\n",
    "    # Load the texts from the pickle file\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        splitters[f\"recursivecharactersplitter_{i}\"] = pickle.load(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
