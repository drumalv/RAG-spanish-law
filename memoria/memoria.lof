\babel@toc {spanish}{}\relax 
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Arquitectura básica de un Transformer.}}{5}{figure.2.1}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Evolución cronológica de los principales LLMs.}}{5}{figure.2.2}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Ejemplo unificado de formación texto a texto, imagen origen de \citep {raffel2020exploring}}}{6}{figure.2.3}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Zero-shot, one-shot y few-shot contrastado con finetunning tradicional. Imagen origen de \citep {brown2020language}}}{7}{figure.2.4}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Ejemplo de chunkerización tamaño fijo sin overload}}{11}{figure.3.1}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Ejemplo de chunkerización tamaño fijo con overload}}{12}{figure.3.2}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces Ejemplo de chunkerización recursiva}}{12}{figure.3.3}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces Ejemplo de chunkerización Especializada}}{13}{figure.3.4}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Esquema de un RAG}}{16}{figure.4.1}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces Esquema de un Self Query retriever \citep {langchainretrievers}}}{18}{figure.4.2}%
\addvspace {10\p@ }
\addvspace {10\p@ }
