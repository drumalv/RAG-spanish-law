\babel@toc {spanish}{}\relax 
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Arquitectura básica de un Transformer.}}{5}{figure.2.1}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Evolución cronológica de los principales LLMs.}}{5}{figure.2.2}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Ejemplo unificado de formación texto a texto, imagen origen de \citep {raffel2020exploring}}}{6}{figure.2.3}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Zero-shot, one-shot y few-shot contrastado con finetunning tradicional. Imagen origen de \citep {brown2020language}}}{7}{figure.2.4}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Flujo de trabajo de RAG mostrando la integración de documentos recuperados para mejorar la generación de texto.}}{12}{figure.3.1}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Ejemplo de chunkerización tamaño fijo sin overload}}{17}{figure.4.1}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces Ejemplo de chunkerización tamaño fijo con overload}}{18}{figure.4.2}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces Ejemplo de chunkerización recursiva}}{18}{figure.4.3}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces Ejemplo de chunkerización Especializada}}{19}{figure.4.4}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Esquema de un RAG}}{22}{figure.5.1}%
\contentsline {figure}{\numberline {5.2}{\ignorespaces Esquema de un Self Query retriever \citep {langchainretrievers}}}{24}{figure.5.2}%
